import streamlit as st
import os
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain_community.document_loaders import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# Setup
st.set_page_config(page_title="Colega", layout="wide")
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# Initialize the language model
llm = ChatOpenAI(model_name='ft:gpt-4o-mini-2024-07-18:personal::9vW8AJQu', temperature=1, )

# Common sentences and predefined responses
common_sentences = [
    "hola", "buenos dÃ­as", "buenas tardes", "buenas noches", "adiÃ³s", "chao", "muchas gracias", "gracias", 
    "gracias!", "para quÃ© estÃ¡s entrenado?", "Â¿cÃ³mo estÃ¡s?", "Â¿quiÃ©n te creÃ³?", "Â¿cuÃ¡l es tu nombre?", 
    "Â¿quÃ© puedes hacer?", "Â¿eres un robot?", "Â¿cÃ³mo me puedes ayudar?", "Â¿trabajas las 24 horas?"
]

def standard_answer(message_body):
    response_text = ""
    if message_body in ["hola", "buenos dÃ­as", "buenas tardes", "buenas noches"]:
        response_text = "Â¡Hola! Hablas con Colega, tu asistente virtual ğŸ¤– Â¿En quÃ© puedo ayudarte hoy? ğŸ¤“"
    elif message_body in ["adiÃ³s", "chao"]:
        response_text = "Â¡Hasta luego! Espero haberte ayudado. ğŸ‘‹ ğŸ‘‹ ğŸ‘‹ ğŸ‘‹"
    elif message_body in ["gracias", "muchas gracias", "gracias!"]:
        response_text = "Â¡Con gusto! Si tienes otra consulta, estoy aquÃ­ para ayudarte ğŸ˜Š"
    elif message_body in ["para quÃ© estÃ¡s entrenado?"]:
        response_text = "Estoy entrenado para brindarte informaciÃ³n sobre nuestra empresa, productos y ayudarte en el proceso de ventas para que tengas mejores resultados. TambiÃ©n puedo responder una gran variedad de consultas ğŸ’¡"
    elif message_body in ["Â¿cÃ³mo estÃ¡s?"]:
        response_text = "Â¡Estoy funcionando al 100%! ğŸ¤– Â¿En quÃ© puedo ayudarte?"
    elif message_body in ["Â¿quiÃ©n te creÃ³?"]:
        response_text = "Fui creado por un equipo de expertos en tecnologÃ­a y automatizaciÃ³n para ayudarte en todo lo que necesites ğŸ“šğŸ”§"
    elif message_body in ["Â¿cuÃ¡l es tu nombre?"]:
        response_text = "Mi nombre es Colega ğŸ¤–, tu asistente virtual siempre disponible para ayudarte."
    elif message_body in ["Â¿quÃ© puedes hacer?"]:
        response_text = "Puedo ayudarte a encontrar informaciÃ³n sobre nuestros productos, gestionar procesos de ventas y responder preguntas frecuentes sobre nuestra empresa ğŸŒŸ"
    elif message_body in ["Â¿eres un robot?"]:
        response_text = "SÃ­, soy un robot asistente virtual diseÃ±ado para ayudarte con informaciÃ³n y consultas ğŸ‘¾"
    elif message_body in ["Â¿cÃ³mo me puedes ayudar?"]:
        response_text = "Puedo proporcionarte informaciÃ³n relevante, ayudarte en procesos de ventas y responder preguntas sobre nuestros productos y servicios ğŸ”"
    elif message_body in ["Â¿trabajas las 24 horas?"]:
        response_text = "Â¡AsÃ­ es! Estoy disponible las 24 horas del dÃ­a, los 7 dÃ­as de la semana, siempre listo para ayudarte ğŸ’ª"
    
    return response_text

# Initialize and configure the retriever for CSV files
@st.cache_resource()
def retriever_func(file_path):
    loader = CSVLoader(file_path=file_path, encoding="utf-8")
    data = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, 
        chunk_overlap=200, 
        add_start_index=True
    )
    all_splits = text_splitter.split_documents(data)

    vectorstore = FAISS.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 6})
    
    return retriever
retriever= retriever_func('987987.csv')
# Main chat application
def chat():
    st.write("# Preguntale a Colega")
    
    # Initialize session state for messages if not already initialized
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    
    user_message = st.chat_input("Escribe tu mensaje aquÃ­...")

    if user_message:
        if user_message in common_sentences:
            final_answer = standard_answer(user_message)
        else:
            # Retrieve context and get response from model
            retrieved_docs = retriever.invoke(user_message)
            context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])
            
            # Prepare the message sequence for the model using the appropriate message classes
            messages = [
                SystemMessage(content=f"Context: {context_text}"),
                HumanMessage(content=user_message)
            ]
            response = llm(messages)
            final_answer = response.content  # Access the content directly
        
        # Add both the user message and the assistant's response to the conversation history
        st.session_state.messages.append({"role": "user", "content": user_message})
        st.session_state.messages.append({"role": "assistant", "content": final_answer})
    
    # Display the entire conversation history
    if st.session_state["messages"]:
        for message in st.session_state["messages"]:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# Sidebar functionalities
def sidebar():
    st.sidebar.title("Opciones")
    
    # Restart button
    if st.sidebar.button("Reiniciar conversaciÃ³n"):
        st.session_state.clear()
        st.experimental_rerun()
    
    # Display CSV content
    if st.sidebar.checkbox("Mostrar base de datos (CSV)"):
        st.sidebar.write("### Contenido del CSV:")
        df = pd.read_csv('987987.csv')  # Load CSV content directly
        st.sidebar.write(df)

# Main App
def main():
    st.markdown(
        """
        <div style='text-align: center;'>
            <h1> ğŸ§  Colega ğŸ§  </h1>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        """
        <div style='text-align: center;'>
            <h4>âš¡ï¸Tu asistente digital</h4>
        </div>
        """,
        unsafe_allow_html=True,
    )
    
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
    
    # Sidebar
    sidebar()

    # Main chat interface
    chat()

if __name__ == "__main__":
    main()
